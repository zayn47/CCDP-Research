{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b6b5c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SET PATH\n",
    "path = f\"{os.getcwd()}/dataset/train.parquet\"\n",
    "# LOAD PARQUET DATASET WITH FEATURE ENGINEERING\n",
    "df = pd.read_parquet(path=path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# REDUCE DTYPE FOR CUSTOMER AND DATE\n",
    "df['customer_ID']= df['customer_ID'].str[-16:].apply(int, base=16)\n",
    "\n",
    "# S_2 is not relevant so lets drop it\n",
    "df.drop(['S_2'],axis=1,inplace=True)\n",
    "# df = df.fillna(-127)\n",
    "# There are multiple transactions. Let's take only the latest transaction from each customer.\n",
    "df= df.groupby('customer_ID').tail(1)\n",
    "df= df.set_index(['customer_ID'])\n",
    "\n",
    "print('shape of data:', df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# all_cols = [c for c in list(df.columns) if c not in ['customer_ID','S_2']]\n",
    "# cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
    "# num_features = [col for col in all_cols if col not in cat_features]\n",
    "#\n",
    "# test_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "# test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "#\n",
    "# test_cat_agg = df.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "# test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "#\n",
    "# df = pd.concat([test_num_agg, test_cat_agg], axis=1)\n",
    "# del test_num_agg, test_cat_agg\n",
    "# print('shape after engineering', df.shape )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read and process Train Labels\n",
    "targets = pd.read_csv(f\"{os.getcwd()}/dataset/train_labels.csv\")\n",
    "targets['customer_ID'] = targets['customer_ID'].str[-16:].apply(int, base=16)\n",
    "targets = targets.set_index('customer_ID')\n",
    "train_data = df.merge(targets, left_index=True, right_index=True, how='left')\n",
    "train_data.target = train_data.target.astype('int8')\n",
    "del targets, df\n",
    "# NEEDED TO MAKE CV DETERMINISTIC (Pandas merge above randomly shuffles rows)\n",
    "train_data = train_data.sort_index().reset_index()\n",
    "\n",
    "# FEATURES\n",
    "FEATURES = train_data.columns[1:-1]\n",
    "print(f'There are {len(FEATURES)} features!')\n",
    "print(\"Train data Shape\", train_data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = train_data.drop(['target','customer_ID'],axis=1)\n",
    "y_train = train_data['target']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split train data into training and testing sets\n",
    "x_train_split, x_test_split, y_train_split, y_test_split = train_test_split(x_train, y_train, test_size=0.20,\n",
    "                                                                            random_state=0,\n",
    "                                                                            stratify=y_train)\n",
    "\n",
    "# Initialize XGB Classifier\n",
    "xgb_cal = xgb.XGBClassifier()\n",
    "xgb_cal.fit(x_train_split,y_train_split)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create StratifiedKFold and train using XGBoost object.\n",
    "kfold = 5\n",
    "skf = StratifiedKFold(n_splits=kfold, shuffle=True, random_state=0)\n",
    "xgb_cal = xgb.XGBClassifier()\n",
    "lst_accu_stratified_test = []\n",
    "lst_accu_stratified_train = []\n",
    "for i, (train_index, test_index) in enumerate(skf.split(x_train, y_train), start=1):\n",
    "    print('[Fold %d/%d]' % (i, kfold))\n",
    "    x_train_split, x_test_split  = x_train[train_index], x_train[test_index]\n",
    "    y_train_split, y_test_split  = y_train[train_index], y_train[test_index]\n",
    "    xgb_cal.fit(x_train_split, y_train_split)\n",
    "    y_predict_test = xgb_cal.predict(x_test_split)\n",
    "    lst_accu_stratified_test.append(accuracy_score(y_test_split, y_predict_test))\n",
    "    y_predict_train = xgb_cal.predict(x_train_split)\n",
    "    lst_accu_stratified_train.append(accuracy_score(y_train_split,y_predict_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Value of 5 Folds with Test Data:\", lst_accu_stratified_test)\n",
    "print(\"V of 5 Folds with Train Data:\", lst_accu_stratified_train)\n",
    "\n",
    "print(\"Mean of Test data Accuracy:\",np.mean(lst_accu_stratified_test))\n",
    "print(\"Mean of Train data Accuracy:\",np.mean(lst_accu_stratified_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define the tree depths to evaluate\n",
    "values = [i for i in range(1, 6)]\n",
    "# plot of train and test scores\n",
    "pyplot.plot(values, lst_accu_stratified_train, '-o', label='Train')\n",
    "pyplot.plot(values, lst_accu_stratified_test, '-o', label='Test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_predict=xgb_cal.predict(x_test_split)\n",
    "\n",
    "test_scores = accuracy_score(y_test_split, y_predict)\n",
    "\n",
    "# Classification Score using test data\n",
    "print('XGBoost Classifier Accuracy: {:.3f}'.format(test_scores))\n",
    "print('\\nXGBoost Classifier Precision: {:.3f}'.format(precision_score (y_test_split, y_predict)))\n",
    "print('\\nXGBoost Classifier Recall: {:.3f}'.format(recall_score (y_test_split, y_predict)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_predict_train=xgb_cal.predict(x_train_split)\n",
    "\n",
    "train_scores = accuracy_score(y_train_split, y_predict_train)\n",
    "\n",
    "# Classification Score using train data to check over and under fitting\n",
    "print('XGBoost Classifier Accuracy: {:.3f}'.format(train_scores))\n",
    "print('\\nXGBoost Classifier Precision: {:.3f}'.format(precision_score (y_train_split, y_predict_train)))\n",
    "print('\\nXGBoost Classifier Recall: {:.3f}'.format(recall_score (y_train_split, y_predict_train)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define the tree depths to evaluate\n",
    "# values = [i for i in range(1, 7)]\n",
    "# plot of train and test scores\n",
    "pyplot.plot(1, train_scores, '-o', label='Train')\n",
    "pyplot.plot(1, test_scores, '-o', label='Test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/327534\n",
    "def amex_metric_mod(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "amex_metric_score_test = amex_metric_mod(y_test_split,y_predict)\n",
    "amex_metric_score_train = amex_metric_mod(y_train_split,y_predict_train)\n",
    "print(\"Amex Metric Score on test data: \", amex_metric_score_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SET TEST DATA PATH\n",
    "path = f\"{os.getcwd()}/dataset/test.parquet\"\n",
    "# LOAD PARQUET DATASET WITH FEATURE ENGINEERING\n",
    "df_test = pd.read_parquet(path=path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# S_2 is not relevant so lets drop it\n",
    "df_test.drop(['S_2'],axis=1,inplace=True)\n",
    "\n",
    "# There are multiple transactions. Let's take only the latest transaction from each customer.\n",
    "df_test= df_test.groupby('custy. omer_ID').tail(1)\n",
    "df_test= df_test.set_index(['customer_ID'])\n",
    "\n",
    "df_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test_predict=xgb_cal.predict_proba(df_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_predict_final=y_test_predict[:,1]\n",
    "submission = pd.DataFrame({\"customer_ID\":df_test.index,\"prediction\":y_predict_final})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}